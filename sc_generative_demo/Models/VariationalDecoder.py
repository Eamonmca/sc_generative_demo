# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/06_Model_Variational_Decoder.ipynb.

# %% auto 0
__all__ = ['VariationalDecoder']

# %% ../../nbs/06_Model_Variational_Decoder.ipynb 3
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

class VariationalDecoder(nn.Module):
    """Variational Decoder model"""
    def __init__(self, input_size, hidden_sizes, output_size, dropout, use_norm):
        super().__init__()
        self.input_size = input_size
        self.output_size = output_size
        self.hidden_sizes = hidden_sizes
        self.dropout = dropout
        self.use_batch_norm = use_norm
        
        
        # create a list of layers
        layers = []

        # input layer
        layers.append(nn.Linear(self.input_size, self.hidden_sizes[0]))
        layers.append(nn.LeakyReLU(0.2))
        if self.dropout > 0:
            layers.append(nn.Dropout(p=self.dropout))

        # hidden layers
        for i in range(1, len(self.hidden_sizes)):
            layers.append(nn.Linear(self.hidden_sizes[i-1], self.hidden_sizes[i]))
            if self.use_batch_norm:
                layers.append(nn.InstanceNorm1d(self.hidden_sizes[i]))
            layers.append(nn.LeakyReLU(0.2))
            if self.dropout > 0:
                layers.append(nn.Dropout(p=self.dropout))
        
        # output layer
        layers.append(nn.Linear(self.hidden_sizes[-1], self.output_size))

        # create the model using Sequential
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)


