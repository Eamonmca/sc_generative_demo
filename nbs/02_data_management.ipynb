{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management\n",
    "\n",
    "> Functionality for preparing single cell data for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp DataManagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import random\n",
    "import math\n",
    "from fastcore.utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "class SplitData:\n",
    "    \"\"\"A class for splitting a Scanpy AnnData object into training, evaluation, and test sets.\"\"\"\n",
    "    def __init__(self, \n",
    "                 scdata, # a Scanpy AnnData object\n",
    "                 train_fraction = 0.8,  # the fraction of the data to use for training\n",
    "                 eval_fraction = 0.2, # the fraction of the data to use for evaluation\n",
    "                 test = False, # whether to include a test set in the split\n",
    "                 random_seed = 1234 # the random seed to use for the split\n",
    "                 ):\n",
    "        self.scdata = scdata\n",
    "        self.train_fraction = train_fraction\n",
    "        self.eval_fraction = eval_fraction\n",
    "        self.test = test\n",
    "        self.random_seed = random_seed\n",
    "        self._check_input()\n",
    "\n",
    "\n",
    "    def _check_input(self):\n",
    "        \"\"\"Check the input parameters for errors.\"\"\"\n",
    "        if self.train_fraction + self.eval_fraction > 1:\n",
    "            raise ValueError(\"train_fraction + eval_fraction should be less than 1\")\n",
    "        if self.train_fraction <= 0:\n",
    "            raise ValueError(\"train_fraction should be greater than 0\")\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\" Split the data into training, evaluation, and (optionally) test sets.\"\"\"\n",
    "        # Initialize the random number generator with the specified seed\n",
    "        if self.random_seed:\n",
    "            random.seed(self.random_seed)\n",
    "            \n",
    "        # Calculate the number of training samples based on the train_fraction\n",
    "        train_size = int(len(self.scdata.obs.index) * self.train_fraction)\n",
    "        # Calculate the number of evaluation samples based on the eval_fraction\n",
    "        eval_size = int(len(self.scdata.obs.index) - train_size)\n",
    "        # If the test flag is set to True\n",
    "        if self.test:\n",
    "            # Calculate the number of test samples by subtracting the number of training and evaluation samples from the total number of samples\n",
    "            eval_size = int(eval_size * self.eval_fraction)\n",
    "            test_size = len(self.scdata.obs.index) - train_size - eval_size\n",
    "            # Generate a list of random indices with the same length as the number of samples\n",
    "            indices = random.sample(range(len(self.scdata.obs.index)), train_size + eval_size + test_size)\n",
    "            # Split the indices into training, evaluation, and test sets\n",
    "            train_indices = indices[:train_size]\n",
    "            eval_indices = indices[train_size:train_size + eval_size]\n",
    "            test_indices = indices[train_size + eval_size:]\n",
    "            # Return the indices for the training, evaluation, and test sets\n",
    "            return [self.scdata.obs.index[i] for i in train_indices], [self.scdata.obs.index[i] for i in eval_indices], [self.scdata.obs.index[i] for i in test_indices]\n",
    "        # If the test flag is set to False\n",
    "        else:\n",
    "            # Generate a list of random indices with the same length as the number of training and evaluation samples\n",
    "            indices = random.sample(range(len(self.scdata.obs.index)), train_size + eval_size)\n",
    "            # Split the indices into training and evaluation sets\n",
    "            train_indices = indices[:train_size]\n",
    "            eval_indices = indices[train_size:]\n",
    "            # Return the indices for the training and evaluation sets\n",
    "            return [self.scdata.obs.index[i] for i in train_indices], [self.scdata.obs.index[i] for i in eval_indices]\n",
    "        \n",
    "    def _split_data(self, scdata, train_fraction, eval_fraction, test=False, random_seed=None):\n",
    "        \"\"\" Split the data into training, evaluation, and (optionally) test sets.\"\"\"\n",
    "        # Initialize the random number generator with the specified seed\n",
    "        if random_seed:\n",
    "            random.seed(random_seed)\n",
    "            \n",
    "        # Calculate the number of training samples based on the train_fraction\n",
    "        train_size = int(len(scdata.obs.index) * train_fraction)\n",
    "        # Calculate the number of evaluation samples based on the eval_fraction\n",
    "        eval_size = int(len(scdata.obs.index) - train_size)\n",
    "        # If the test flag is set to True\n",
    "        if test:\n",
    "            # Calculate the number of test samples by subtracting the number of training and evaluation samples from the total number of samples\n",
    "            eval_size = int(eval_size * eval_fraction)\n",
    "            test_size = len(scdata.obs.index) - train_size - eval_size\n",
    "            # Generate a list of random indices with the same length as the number of samples\n",
    "            indices = random.sample(range(len(scdata.obs.index)), train_size + eval_size + test_size)\n",
    "            # Split the indices into training, evaluation, and test sets\n",
    "            train_indices = indices[:train_size]\n",
    "            eval_indices = indices[train_size:train_size + eval_size]\n",
    "            test_indices = indices[train_size + eval_size:]\n",
    "            # Return the indices for the training, evaluation, and test sets\n",
    "            return [scdata.obs.index[i] for i in train_indices], [scdata.obs.index[i] for i in eval_indices], [scdata.obs.index[i] for i in test_indices]\n",
    "        # If the test flag is set to False\n",
    "        else:\n",
    "            # Generate a list of random indices with the same length as the number of training and evaluation samples\n",
    "            indices = random.sample(range(len(scdata.obs.index)), train_size + eval_size)\n",
    "            # Split the indices into training and evaluation sets\n",
    "            train_indices = indices[:train_size]\n",
    "            eval_indices = indices[train_size:]\n",
    "            # Return the indices for the training and evaluation sets\n",
    "            return [scdata.obs.index[i] for i in train_indices], [scdata.obs.index[i] for i in eval_indices]\n",
    "\n",
    "        \n",
    "    def split_data_stratified(self, stratify_by):\n",
    "        \"\"\" Split the data into training, evaluation, and (optionally) test sets stratified by the specified factor\"\"\"\n",
    "        \n",
    "        # Get the unique classes from the stratify_by column\n",
    "        classes = self.scdata.obs[stratify_by].unique()\n",
    "        \n",
    "        # Lists to store the indices of the split data\n",
    "        train_idxs = []\n",
    "        evaluation_idxs = []\n",
    "        \n",
    "        # If test set is requested, create an empty list to store its indices\n",
    "        if self.test:\n",
    "            test_idxs = []\n",
    "        \n",
    "        # For each class in the data\n",
    "        for batch in classes:\n",
    "            # Split the data for this class into training, evaluation, and (if requested) test sets\n",
    "            if self.test:\n",
    "                train_idx, eval_idx, test_idx = self._split_data(self.scdata[self.scdata.obs[stratify_by] == batch], train_fraction=self.train_fraction, eval_fraction=self.eval_fraction, test=self.test, random_seed=self.random_seed)\n",
    "                # Add the indices for this class to the overall list of indices\n",
    "                train_idxs.extend(train_idx)\n",
    "                evaluation_idxs.extend(eval_idx)\n",
    "                test_idxs.extend(test_idx)\n",
    "            else:\n",
    "                # Split the data for this class into training and evaluation sets\n",
    "                train_idx, eval_idx = self._split_data(self.scdata[self.scdata.obs[stratify_by] == batch], train_fraction=self.train_fraction, eval_fraction=self.eval_fraction, test=self.test, random_seed=self.random_seed)\n",
    "                # Add the indices for this class to the overall list of indices\n",
    "                train_idxs.extend(train_idx)\n",
    "                evaluation_idxs.extend(eval_idx)\n",
    "        \n",
    "        # If a test set was requested, check that the sets are disjoint and their union is the full set of indices\n",
    "        if self.test:\n",
    "            assert set(train_idxs).intersection(set(evaluation_idxs)) == set()\n",
    "            assert set(train_idxs).intersection(set(test_idxs)) == set()\n",
    "            assert set(evaluation_idxs).intersection(set(test_idxs)) == set()\n",
    "            assert len(train_idxs) + len(evaluation_idxs) + len(test_idxs) == len(self.scdata.obs.index)\n",
    "            \n",
    "            \n",
    "            # Return the indices for the training, evaluation, and test sets\n",
    "            return list(train_idxs), list(evaluation_idxs), list(test_idxs)\n",
    "        else:\n",
    "            # Check that the training and evaluation sets are disjoint and their union is the full set of indices\n",
    "            assert set(train_idxs).intersection(set(evaluation_idxs)) == set()\n",
    "            assert len(train_idxs) + len(evaluation_idxs) == len(self.scdata.obs.index)\n",
    "            \n",
    "            # Return the indices for the training and evaluation sets\n",
    "            return list(train_idxs), list(evaluation_idxs)\n",
    "\n",
    "    \n",
    "    def pct_summary(self, idxs_list, stratify_by):\n",
    "        \"\"\" Return a dataframe summarizing the percentage of samples in each class for each subset of the data\"\"\"\n",
    "        \n",
    "        # If there are two subsets of the data\n",
    "        if len(idxs_list) == 2:\n",
    "            # Concatenate the value counts of the stratify_by column for each subset, normalizing so that they sum to 1\n",
    "            df = pd.concat([self.scdata[idxs_list[0]].obs[stratify_by].value_counts(normalize=True), self.scdata[idxs_list[1]].obs[stratify_by].value_counts(normalize=True)], axis=1)\n",
    "            # Rename the columns of the dataframe\n",
    "            df.columns = [\"train\", \"eval\"]\n",
    "            # Return the dataframe\n",
    "            return df\n",
    "        # If there are three subsets of the data\n",
    "        elif len(idxs_list) == 3:\n",
    "            # Concatenate the value counts of the stratify_by column for each subset, normalizing so that they sum to 1\n",
    "            df = pd.concat([self.scdata[idxs_list[0]].obs[stratify_by].value_counts(normalize=True), self.scdata[idxs_list[1]].obs[stratify_by].value_counts(normalize=True), self.scdata[idxs_list[2]].obs[stratify_by].value_counts(normalize=True)], axis=1)\n",
    "            # Rename the columns of the dataframe\n",
    "            df.columns = [\"train\", \"eval\", \"test\"]\n",
    "            # Return the dataframe\n",
    "            return df\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Meta:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(Meta)\n",
    "def strip(scdata, filters, copy = False, verbose = False):\n",
    "    possible_dims = [\"obs\", \"var\", \"obsm\", \"varm\", \"uns\", \"obsp\", \"varp\"]\n",
    "    keep = set ([dim for dim, _ in filters]).intersection(set(possible_dims))\n",
    "    striped_items_dict = {}\n",
    "    \n",
    "    if copy:\n",
    "        for dim in possible_dims:\n",
    "                for key in list(scdata.__getattribute__(dim).keys()):\n",
    "                    if key not in [k for d, ks in filters for k in ks]:\n",
    "                        inner_dict = scdata.__getattribute__(dim).pop(key)\n",
    "                        if dim not in striped_items_dict:\n",
    "                            striped_items_dict[str(dim)] = {}\n",
    "                            striped_items_dict[dim][key] = inner_dict\n",
    "                    if verbose:\n",
    "                        print(f\"Removing {key} from {dim}\")\n",
    "        return scdata, striped_items_dict\n",
    "    else:\n",
    "        for dim in possible_dims:\n",
    "                for key in list(scdata.__getattribute__(dim).keys()):\n",
    "                    if key not in [k for d, ks in filters for k in ks]:\n",
    "                        scdata.__getattribute__(dim).pop(key)\n",
    "                        if verbose:\n",
    "                            print(f\"Removing {key} from {dim}\")\n",
    "        return scdata\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(Meta)\n",
    "def sew(scdata, stripped_items, verbose = False):\n",
    "    for dim in stripped_items:\n",
    "        for key in stripped_items[dim]:\n",
    "            scdata.__getattribute__(dim)[key] = stripped_items[dim][key]\n",
    "            if verbose:\n",
    "                print(f\"Adding {key} to {dim}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scINTEGRATION",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
