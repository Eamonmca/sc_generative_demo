{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAEGAN NEGATIVE BINOMIAL\n",
    "\n",
    "> The VAEGAN model, takes an Variational Encoder, Variational Decoder and Classifier model as inputs. Uses a negative binomial as the latent variable rather than Gausian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Models.VAEGAN_NEG_BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/Users/eamonmcandrew/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/Users/eamonmcandrew/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import scvi\n",
    "from scvi.models.distributions import NegativeBinomial\n",
    "from torch.distributions import Normal\n",
    "\n",
    "class VAEGAN_NEG_BI(nn.Module):\n",
    "    def __init__(self, encoder_z, encoder_l, decoder_px, decoder_r, classifier, log = True):\n",
    "        \"\"\"\n",
    "        The VAEGAN model with Negative Binomial distribution as Latent Variable\n",
    "        \"\"\"\n",
    "        super(VAEGAN_NEG_BI, self).__init__()\n",
    "        self.encoder_z = encoder_z\n",
    "        self.encoder_l = encoder_l\n",
    "        self.decoder_px = decoder_px\n",
    "        self.decoder_r = decoder_r\n",
    "      \n",
    "        \n",
    "        self.classifier = classifier\n",
    "    \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # var = torch.exp(logvar) + 1e-4\n",
    "        z = Normal(mu, logvar.sqrt()).rsample()\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z, l, train = True):\n",
    "        h_x = self.decoder_px(z) \n",
    "        h_x = F.relu(h_x)\n",
    "        h_r = self.decoder_r(h_x)      \n",
    "        h_r = F.softmax(h_r)\n",
    "        h_p = torch.exp(l) * h_r\n",
    "        x_hat = NegativeBinomial(mu =h_r, theta = h_p).sample()\n",
    "        return x_hat, h_r, h_p\n",
    "\n",
    "\n",
    "    def forward(self, x, log=True):\n",
    "        if log :\n",
    "            x= torch.log(x+1)\n",
    "        mu_l, logvar_l = self.encoder_l(x)\n",
    "        mu_z, logvar_z = self.encoder_z(x)\n",
    "        \n",
    "        l = self.reparameterize(mu_l, logvar_l)\n",
    "        l = torch.clamp(l, max=12)\n",
    "        z = self.reparameterize(mu_z, logvar_z)\n",
    "        \n",
    "        x_hat, h_r, h_p = self.decode(z,l)\n",
    "        \n",
    "        y_hat = self.classifier(z) \n",
    "        \n",
    "        return x_hat, y_hat, mu_z, logvar_z, mu_l, logvar_l, h_r, h_p, l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unexpected format in '/Users/eamonmcandrew/Desktop/Single_cell_integration/scgenerative_demo/sc_generative_demo/Models/VAEGAN_NEG_BI.py' at cell:\n```\n# %% ../../nbs/11_Model_VAEGAN_NEG_BI copy.ipynb 3\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport scvi\nfrom scvi.models.distributions import NegativeBinomial\nfrom torch.distributions import Normal\n\nclass VAEGAN_NEG_BI(nn.Module):\n    def __init__(self, encoder_z, encoder_l, decoder_px, decoder_r, classifier, log = True):\n        \"\"\"\n        The VAEGAN model with Negative Binomial distribution as Latent Variable\n        \"\"\"\n        super(VAEGAN_NEG_BI, self).__init__()\n        self.encoder_z = encoder_z\n        self.encoder_l = encoder_l\n        self.decoder_px = decoder_px\n        self.decoder_r = decoder_r\n      \n        \n        self.classifier = classifier\n    \n        \n    def reparameterize(self, mu, logvar):\n        # var = torch.exp(logvar) + 1e-4\n        z = Normal(mu, logvar.sqrt()).rsample()\n        return z\n    \n    def decode(self, z, l, train = True):\n        h_x = self.decoder_px(z) \n        h_x = F.relu(h_x)\n        h_r = self.decoder_r(h_x)      \n        h_r = F.softmax(h_r)\n        h_p = torch.exp(l) * h_r\n        x_hat = NegativeBinomial(mu =h_r, theta = h_p).sample()\n        return x_hat, h_r, h_p\n\n\n    def forward(self, x, log=True):\n        if log :\n            x= torch.log(x+1)\n        mu_l, logvar_l = self.encoder_l(x)\n        mu_z, logvar_z = self.encoder_z(x)\n        \n        l = self.reparameterize(mu_l, logvar_l)\n        l = torch.clamp(l, max=12)\n        z = self.reparameterize(mu_z, logvar_z)\n        \n        x_hat, h_r, h_p = self.decode(z,l)\n        \n        y_hat = self.classifier(z) \n        \n        return x_hat, y_hat, mu_z, logvar_z, mu_l, logvar_l, h_r, h_p, l.\n```\nThe expected format is: '# %% {nb_path} {cell_idx}'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/nbdev/doclinks.py:52\u001b[0m, in \u001b[0;36m_iter_py_cells\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     51\u001b[0m top,code \u001b[39m=\u001b[39m cell\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[39mtry\u001b[39;00m: nb,idx \u001b[39m=\u001b[39m top\u001b[39m.\u001b[39msplit()\n\u001b[1;32m     53\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/eamonmcandrew/Desktop/Single_cell_integration/scgenerative_demo/nbs/11_Model_VAEGAN_NEG_BI copy.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eamonmcandrew/Desktop/Single_cell_integration/scgenerative_demo/nbs/11_Model_VAEGAN_NEG_BI%20copy.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#| hide\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eamonmcandrew/Desktop/Single_cell_integration/scgenerative_demo/nbs/11_Model_VAEGAN_NEG_BI%20copy.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnbdev\u001b[39;00m; nbdev\u001b[39m.\u001b[39;49mnbdev_export()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/fastcore/script.py:110\u001b[0m, in \u001b[0;36mcall_parse.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_f\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    109\u001b[0m     mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(inspect\u001b[39m.\u001b[39mcurrentframe()\u001b[39m.\u001b[39mf_back)\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mod: \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SCRIPT_INFO\u001b[39m.\u001b[39mfunc \u001b[39mand\u001b[39;00m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m: SCRIPT_INFO\u001b[39m.\u001b[39mfunc \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sys\u001b[39m.\u001b[39margv)\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m sys\u001b[39m.\u001b[39margv[\u001b[39m1\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m: sys\u001b[39m.\u001b[39margv\u001b[39m.\u001b[39mpop(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/nbdev/doclinks.py:139\u001b[0m, in \u001b[0;36mnbdev_export\u001b[0;34m(path, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files: nb_export(f)\n\u001b[1;32m    138\u001b[0m add_init(get_config()\u001b[39m.\u001b[39mlib_path)\n\u001b[0;32m--> 139\u001b[0m _build_modidx()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/nbdev/doclinks.py:101\u001b[0m, in \u001b[0;36m_build_modidx\u001b[0;34m(dest, nbs_path, skip_exists)\u001b[0m\n\u001b[1;32m     99\u001b[0m code_root \u001b[39m=\u001b[39m dest\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mresolve()\n\u001b[1;32m    100\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m globtastic(dest, file_glob\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*.py\u001b[39m\u001b[39m\"\u001b[39m, skip_file_re\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m^_\u001b[39m\u001b[39m'\u001b[39m, skip_folder_re\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.ipynb_checkpoints\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 101\u001b[0m     res[\u001b[39m'\u001b[39m\u001b[39msyms\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mupdate(_get_modidx((dest\u001b[39m.\u001b[39;49mparent\u001b[39m/\u001b[39;49mfile)\u001b[39m.\u001b[39;49mresolve(), code_root, nbs_path\u001b[39m=\u001b[39;49mnbs_path))\n\u001b[1;32m    102\u001b[0m idxfile\u001b[39m.\u001b[39mwrite_text(\u001b[39m\"\u001b[39m\u001b[39m# Autogenerated by nbdev\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39md = \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mpformat(res, width\u001b[39m=\u001b[39m\u001b[39m140\u001b[39m, indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, compact\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/nbdev/doclinks.py:72\u001b[0m, in \u001b[0;36m_get_modidx\u001b[0;34m(py_path, code_root, nbs_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m _def_types \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mFunctionDef,ast\u001b[39m.\u001b[39mAsyncFunctionDef,ast\u001b[39m.\u001b[39mClassDef\n\u001b[1;32m     71\u001b[0m d \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m _iter_py_cells(py_path):\n\u001b[1;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m cell\u001b[39m.\u001b[39mnb \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     loc \u001b[39m=\u001b[39m _nbpath2html(cell\u001b[39m.\u001b[39mnb_path\u001b[39m.\u001b[39mrelative_to(nbs_path))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/nbdev/doclinks.py:54\u001b[0m, in \u001b[0;36m_iter_py_cells\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m: nb,idx \u001b[39m=\u001b[39m top\u001b[39m.\u001b[39msplit()\n\u001b[1;32m     53\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected format in \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m at cell:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m# %% \u001b[39m\u001b[39m{\u001b[39;00mcell\u001b[39m.\u001b[39mstrip()\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m                               \u001b[39m\"\u001b[39m\u001b[39mThe expected format is: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m# \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{nb_path}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{cell_idx}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m nb_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m nb\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m (p\u001b[39m.\u001b[39mparent\u001b[39m/\u001b[39mnb)\u001b[39m.\u001b[39mresolve()  \u001b[39m# NB paths are stored relative to .py file\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m code\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m): code\u001b[39m=\u001b[39mcode[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unexpected format in '/Users/eamonmcandrew/Desktop/Single_cell_integration/scgenerative_demo/sc_generative_demo/Models/VAEGAN_NEG_BI.py' at cell:\n```\n# %% ../../nbs/11_Model_VAEGAN_NEG_BI copy.ipynb 3\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport scvi\nfrom scvi.models.distributions import NegativeBinomial\nfrom torch.distributions import Normal\n\nclass VAEGAN_NEG_BI(nn.Module):\n    def __init__(self, encoder_z, encoder_l, decoder_px, decoder_r, classifier, log = True):\n        \"\"\"\n        The VAEGAN model with Negative Binomial distribution as Latent Variable\n        \"\"\"\n        super(VAEGAN_NEG_BI, self).__init__()\n        self.encoder_z = encoder_z\n        self.encoder_l = encoder_l\n        self.decoder_px = decoder_px\n        self.decoder_r = decoder_r\n      \n        \n        self.classifier = classifier\n    \n        \n    def reparameterize(self, mu, logvar):\n        # var = torch.exp(logvar) + 1e-4\n        z = Normal(mu, logvar.sqrt()).rsample()\n        return z\n    \n    def decode(self, z, l, train = True):\n        h_x = self.decoder_px(z) \n        h_x = F.relu(h_x)\n        h_r = self.decoder_r(h_x)      \n        h_r = F.softmax(h_r)\n        h_p = torch.exp(l) * h_r\n        x_hat = NegativeBinomial(mu =h_r, theta = h_p).sample()\n        return x_hat, h_r, h_p\n\n\n    def forward(self, x, log=True):\n        if log :\n            x= torch.log(x+1)\n        mu_l, logvar_l = self.encoder_l(x)\n        mu_z, logvar_z = self.encoder_z(x)\n        \n        l = self.reparameterize(mu_l, logvar_l)\n        l = torch.clamp(l, max=12)\n        z = self.reparameterize(mu_z, logvar_z)\n        \n        x_hat, h_r, h_p = self.decode(z,l)\n        \n        y_hat = self.classifier(z) \n        \n        return x_hat, y_hat, mu_z, logvar_z, mu_l, logvar_l, h_r, h_p, l.\n```\nThe expected format is: '# %% {nb_path} {cell_idx}'."
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLL_loss(data, h_r, h_p):\n",
    "    \n",
    "    data = data.view(-1, 1)\n",
    "    ll = torch.distributions.negative_binomial.NegativeBinomial(h_r, h_p)\n",
    "\n",
    "    neg_ll = -torch.mean(torch.sum(ll, dim=-1))\n",
    "    return neg_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scINTEGRATION",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
